!pip install emnist

import tensorflow as tf
from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, Reshape, Conv2DTranspose, Lambda
from tensorflow.keras import backend as K
from tensorflow.keras.models import Model
import numpy as np
from emnist import extract_training_samples, extract_test_samples
from tensorflow.keras.callbacks import ReduceLROnPlateau
from tensorflow import keras

img_dim = 28
filters = 64
intermediate_dim = 256
num_classes = 26
latent_dim = 10
num_components = 30

# VAE model
encoder_inputs = Input(shape=(img_dim, img_dim, 1))
h = encoder_inputs

h = Conv2D(filters=filters, kernel_size=3, padding='same', activation='relu')(h)
h = Conv2D(filters=filters, kernel_size=3, padding='same', activation='relu')(h)
h = Conv2D(filters=filters*2, kernel_size=3, padding='same', activation='relu', strides=2)(h)
h = Conv2D(filters=filters*2, kernel_size=3, padding='same', activation='relu')(h)
h = Conv2D(filters=filters*2, kernel_size=3, padding='same', activation='relu', strides=2)(h)

h_shape = K.int_shape(h)[1:]
h = Flatten()(h)

# Mean and variance components
z_mean = Dense(latent_dim * num_components)(h)
z_log_var = Dense(latent_dim * num_components)(h)

# Sampling Function
def sampling(args):
    z_mean, z_log_var = args
    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim * num_components), mean=0., stddev=1.)
    z_mean = K.reshape(z_mean, (-1, num_components, latent_dim))
    z_log_var = K.reshape(z_log_var, (-1, num_components, latent_dim))
    epsilon = K.reshape(epsilon, (-1, num_components, latent_dim))
    z = z_mean + K.exp(0.5 * z_log_var) * epsilon
    return K.reshape(z, (-1, latent_dim * num_components))

z = Lambda(sampling)([z_mean, z_log_var])

decoder_inputs = Dense(np.prod(h_shape), activation='relu')(z)
decoder_inputs = Reshape(h_shape)(decoder_inputs)
decoder_outputs = Conv2DTranspose(filters=filters*2, kernel_size=3, padding='same', activation='relu')(decoder_inputs)
decoder_outputs = Conv2DTranspose(filters=filters*2, kernel_size=3, padding='same', activation='relu', strides=2)(decoder_outputs)
decoder_outputs = Conv2DTranspose(filters=filters*2, kernel_size=3, padding='same', activation='relu')(decoder_outputs)
decoder_outputs = Conv2DTranspose(filters=filters, kernel_size=3, padding='same', activation='relu', strides=2)(decoder_outputs)
decoder_outputs = Conv2DTranspose(filters=filters, kernel_size=3, padding='same', activation='relu')(decoder_outputs)

# Parameters of the mixed Gaussian distribution
mixture_params = Conv2D(filters=3 * num_components, kernel_size=3, padding='same')(decoder_outputs)
decoder_outputs = tf.concat([mixture_params], axis=-1)

vae = Model(encoder_inputs, decoder_outputs, name='vae')

# Custom Loss Layers
class MixtureGaussianLossLayer(tf.keras.layers.Layer):
    def __init__(self, num_components, **kwargs):
        super(MixtureGaussianLossLayer, self).__init__(**kwargs)
        self.num_components = num_components

    def call(self, inputs):
        y_true, y_pred = inputs
        y_true = tf.cast(y_true, tf.float32)  # 转换数据类型
        reconstruction_loss = tf.keras.losses.binary_crossentropy(y_true, y_pred) * 784

        y_pred = K.reshape(y_pred, (-1, img_dim, img_dim, num_components))
        y_true = K.repeat_elements(K.expand_dims(y_true, axis=1), num_components, axis=1)

        mean_pred = y_pred[..., 0]
        log_var_pred = y_pred[..., 1]
        weights_pred = y_pred[..., 2]

        kl_loss = -0.5 * K.sum(1 + log_var_pred - K.square(mean_pred) - K.exp(log_var_pred), axis=-1)
        kl_loss = K.sum(K.exp(weights_pred) * kl_loss, axis=-1)

        return K.mean(reconstruction_loss + kl_loss)

loss_layer = MixtureGaussianLossLayer(num_components=num_components)

def mixture_gaussian_loss(y_true, y_pred, _=None):
    y_true = tf.cast(y_true, tf.float32)  # Convert data type
    y_pred = K.reshape(y_pred, (-1, img_dim, img_dim, num_components * 3))
    reconstruction_loss = tf.keras.losses.binary_crossentropy(y_true, y_pred) * 784

    mean_pred = y_pred[..., 0]
    log_var_pred = y_pred[..., 1]
    weights_pred = y_pred[..., 2]

    kl_loss = -0.5 * K.sum(1 + log_var_pred - K.square(mean_pred) - K.exp(log_var_pred), axis=-1)
    kl_loss = K.expand_dims(kl_loss, axis=-1)  # Add an extra dimension
    kl_loss = K.repeat_elements(kl_loss, img_dim, axis=-1)  # Repeat along the last axis
    kl_loss = K.reshape(kl_loss, (-1, img_dim, img_dim))  # Reshape to match reconstruction loss dimensions

    return K.mean(reconstruction_loss + kl_loss)

# Data Enhancement
data_generator = tf.keras.preprocessing.image.ImageDataGenerator(
    rotation_range=10,
    width_shift_range=0.1,
    height_shift_range=0.1,
    zoom_range=0.1,
    horizontal_flip=True
)

optimizer = tf.keras.optimizers.Adam(lr=0.0005)
vae.compile(optimizer=optimizer, loss=mixture_gaussian_loss)

# Learning rate decay
reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, min_lr=0.00001)

(x_train, y_train), (x_test, y_test) = extract_training_samples('letters'), extract_test_samples('letters')
#(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()

x_train = x_train.astype('float32') / 255.
x_test = x_test.astype('float32') / 255.
x_train = x_train.reshape((-1, img_dim, img_dim, 1))
x_test = x_test.reshape((-1, img_dim, img_dim, 1))

vae.fit(data_generator.flow(x_train, x_train, batch_size=256),
        steps_per_epoch=len(x_train) // 256,
        epochs=20, callbacks=[reduce_lr])

reconstructions = vae.predict(x_test)

import matplotlib.pyplot as plt

n = 10  # 可视化的图像数量
plt.figure(figsize=(20, 4))
for i in range(n):
    # Original Images
    ax = plt.subplot(2, n, i + 1)
    plt.imshow(x_test[i].reshape(img_dim, img_dim))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    # Reconstructed images
    ax = plt.subplot(2, n, i + 1 + n)
    plt.imshow(reconstructions[i, :, :, 0].reshape(img_dim, img_dim))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

plt.show()
from sklearn.metrics import adjusted_rand_score
from sklearn.cluster import KMeans  # Import KMeans from the correct module

# Obtaining potential spatial representations
encoder = Model(inputs=encoder_inputs, outputs=z_mean)
latent_space = encoder.predict(x_test)

num_runs = 5 
ari_scores = []

for _ in range(num_runs):
    # Clustering in latent space
    kmeans = KMeans(n_clusters=num_classes)
    clusters = kmeans.fit_predict(latent_space)

    # Evaluate clustering performance and record ARI
    ari_score = adjusted_rand_score(y_test, clusters)
    ari_scores.append(ari_score)

# Caclulate Average ARI
average_ari = sum(ari_scores) / num_runs
print("Average ARI）：", average_ari)
import matplotlib.pyplot as plt

# Scatterplotting
plt.figure(figsize=(8, 6))
plt.scatter(latent_space[:, 0], latent_space[:, 1], c=y_test, cmap='viridis')
plt.colorbar()
plt.title("True Labels")
plt.show()

plt.figure(figsize=(8, 6))
plt.scatter(latent_space[:, 0], latent_space[:, 1], c=clusters, cmap='viridis')
plt.colorbar()
plt.title("Predicted Clusters")
plt.show()
